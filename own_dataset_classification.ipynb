{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fbe74672-9108-4f66-a465-aa574d49ba2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import random\n",
    "\n",
    "fruits = np.random.choice([\"Apple\", \"Orange\", \"Pear\"], size=1000)\n",
    "diameter = []\n",
    "weight = []\n",
    "color = []\n",
    "\n",
    "for mark in fruits:\n",
    "    if mark == \"Apple\":\n",
    "        d = random.randint(6, 8)\n",
    "        diameter.append(d)\n",
    "        w = random.randint(30, 40)\n",
    "        weight.append(w)\n",
    "        c = random.uniform(0,1.5)\n",
    "        color.append(c)\n",
    "    if mark == \"Orange\":\n",
    "        d = random.randint(6, 8)\n",
    "        diameter.append(d)\n",
    "        w = random.randint(30, 40)\n",
    "        weight.append(w)\n",
    "        c = random.uniform(1,2.5)\n",
    "        color.append(c)\n",
    "    if mark == \"Pear\":\n",
    "        d = random.randint(6, 8)\n",
    "        diameter.append(d)\n",
    "        w = random.randint(25, 35)\n",
    "        weight.append(w)\n",
    "        c = random.uniform(2,3.5)\n",
    "        color.append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be44d27-c65d-4913-a6ff-3665f9959e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the features into a single matrix\n",
    "X = np.column_stack((diameter, weight, color))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b990cc7-957d-4157-b7e6-4dbc325fd559",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 6,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 8,\n",
       " 7,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 8,\n",
       " 6,\n",
       " 6,\n",
       " 8]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba2e5439-4bef-4b7f-aaaa-84fba99d678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c1e4a02-edba-4af4-aeda-c160b20da48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
    "test_size=0.2, random_state=42)\n",
    "\n",
    "# further split the training set into training and validation sets\n",
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n",
    "#test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4175e0-ca5e-43ff-ad33-5658a09ea328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.        , 37.        ,  1.21697593],\n",
       "       [ 8.        , 32.        ,  2.31578062],\n",
       "       [ 8.        , 32.        ,  1.52747062],\n",
       "       ...,\n",
       "       [ 8.        , 32.        ,  2.05033583],\n",
       "       [ 8.        , 40.        ,  1.05926599],\n",
       "       [ 6.        , 39.        ,  2.37602551]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961456b7-a69d-455e-9bbe-26a2c7ba3da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = [\"Nearest_Neighbors\", \"Linear_SVM\", \"Polynomial_SVM\", \"RBF_SVM\", \"Gaussian_Process\",\n",
    "         \"Gradient_Boosting\", \"Decision_Tree\", \"Extra_Trees\", \"Random_Forest\", \"Neural_Net\", \"AdaBoost\",\n",
    "         \"Naive_Bayes\", \"QDA\", \"SGD\"]\n",
    "#GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "#GaussianProcessClassifier(kernel=custom_kernel()),\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(kernel=\"poly\", degree=3, C=0.025),\n",
    "    SVC(kernel=\"rbf\", C=1, gamma=2),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    GradientBoostingClassifier(n_estimators=100, learning_rate=1.0),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    ExtraTreesClassifier(n_estimators=10, min_samples_split=2),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=100),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(algorithm=\"SAMME\", n_estimators=100),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "    SGDClassifier(loss=\"hinge\", penalty=\"l2\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b7a9e57-71e2-4421-88a1-7e6fcbe48bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    score = clf.score(X_test, Y_test)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f034f799-3f13-4ff6-a78c-d32ec04ed7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gaussian_Process</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient_Boosting</td>\n",
       "      <td>0.840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SGD</td>\n",
       "      <td>0.835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nearest_Neighbors</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>QDA</td>\n",
       "      <td>0.820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RBF_SVM</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random_Forest</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Naive_Bayes</td>\n",
       "      <td>0.815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear_SVM</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision_Tree</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Extra_Trees</td>\n",
       "      <td>0.810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Neural_Net</td>\n",
       "      <td>0.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial_SVM</td>\n",
       "      <td>0.460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 name  score\n",
       "4    Gaussian_Process  0.840\n",
       "5   Gradient_Boosting  0.840\n",
       "10           AdaBoost  0.835\n",
       "13                SGD  0.835\n",
       "0   Nearest_Neighbors  0.820\n",
       "12                QDA  0.820\n",
       "3             RBF_SVM  0.815\n",
       "8       Random_Forest  0.815\n",
       "11        Naive_Bayes  0.815\n",
       "1          Linear_SVM  0.810\n",
       "6       Decision_Tree  0.810\n",
       "7         Extra_Trees  0.810\n",
       "9          Neural_Net  0.805\n",
       "2      Polynomial_SVM  0.460"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['name'] = names\n",
    "df['score'] = scores\n",
    "df = df.sort_values(by=['score'], ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "955bfb09-b25b-4f16-898a-34251c9bfd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3961c_row0_col1, #T_3961c_row1_col1 {\n",
       "  background-color: #008000;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3961c_row2_col1, #T_3961c_row3_col1 {\n",
       "  background-color: #038103;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3961c_row4_col1, #T_3961c_row5_col1 {\n",
       "  background-color: #0c860c;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3961c_row6_col1, #T_3961c_row7_col1, #T_3961c_row8_col1 {\n",
       "  background-color: #0f870f;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3961c_row9_col1, #T_3961c_row10_col1, #T_3961c_row11_col1 {\n",
       "  background-color: #128912;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3961c_row12_col1 {\n",
       "  background-color: #158a15;\n",
       "  color: #f1f1f1;\n",
       "}\n",
       "#T_3961c_row13_col1 {\n",
       "  background-color: #ebf3eb;\n",
       "  color: #000000;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3961c\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3961c_level0_col0\" class=\"col_heading level0 col0\" >name</th>\n",
       "      <th id=\"T_3961c_level0_col1\" class=\"col_heading level0 col1\" >score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row0\" class=\"row_heading level0 row0\" >4</th>\n",
       "      <td id=\"T_3961c_row0_col0\" class=\"data row0 col0\" >Gaussian_Process</td>\n",
       "      <td id=\"T_3961c_row0_col1\" class=\"data row0 col1\" >0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row1\" class=\"row_heading level0 row1\" >5</th>\n",
       "      <td id=\"T_3961c_row1_col0\" class=\"data row1 col0\" >Gradient_Boosting</td>\n",
       "      <td id=\"T_3961c_row1_col1\" class=\"data row1 col1\" >0.840000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row2\" class=\"row_heading level0 row2\" >10</th>\n",
       "      <td id=\"T_3961c_row2_col0\" class=\"data row2 col0\" >AdaBoost</td>\n",
       "      <td id=\"T_3961c_row2_col1\" class=\"data row2 col1\" >0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row3\" class=\"row_heading level0 row3\" >13</th>\n",
       "      <td id=\"T_3961c_row3_col0\" class=\"data row3 col0\" >SGD</td>\n",
       "      <td id=\"T_3961c_row3_col1\" class=\"data row3 col1\" >0.835000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row4\" class=\"row_heading level0 row4\" >0</th>\n",
       "      <td id=\"T_3961c_row4_col0\" class=\"data row4 col0\" >Nearest_Neighbors</td>\n",
       "      <td id=\"T_3961c_row4_col1\" class=\"data row4 col1\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row5\" class=\"row_heading level0 row5\" >12</th>\n",
       "      <td id=\"T_3961c_row5_col0\" class=\"data row5 col0\" >QDA</td>\n",
       "      <td id=\"T_3961c_row5_col1\" class=\"data row5 col1\" >0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row6\" class=\"row_heading level0 row6\" >3</th>\n",
       "      <td id=\"T_3961c_row6_col0\" class=\"data row6 col0\" >RBF_SVM</td>\n",
       "      <td id=\"T_3961c_row6_col1\" class=\"data row6 col1\" >0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row7\" class=\"row_heading level0 row7\" >8</th>\n",
       "      <td id=\"T_3961c_row7_col0\" class=\"data row7 col0\" >Random_Forest</td>\n",
       "      <td id=\"T_3961c_row7_col1\" class=\"data row7 col1\" >0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row8\" class=\"row_heading level0 row8\" >11</th>\n",
       "      <td id=\"T_3961c_row8_col0\" class=\"data row8 col0\" >Naive_Bayes</td>\n",
       "      <td id=\"T_3961c_row8_col1\" class=\"data row8 col1\" >0.815000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row9\" class=\"row_heading level0 row9\" >1</th>\n",
       "      <td id=\"T_3961c_row9_col0\" class=\"data row9 col0\" >Linear_SVM</td>\n",
       "      <td id=\"T_3961c_row9_col1\" class=\"data row9 col1\" >0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row10\" class=\"row_heading level0 row10\" >6</th>\n",
       "      <td id=\"T_3961c_row10_col0\" class=\"data row10 col0\" >Decision_Tree</td>\n",
       "      <td id=\"T_3961c_row10_col1\" class=\"data row10 col1\" >0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row11\" class=\"row_heading level0 row11\" >7</th>\n",
       "      <td id=\"T_3961c_row11_col0\" class=\"data row11 col0\" >Extra_Trees</td>\n",
       "      <td id=\"T_3961c_row11_col1\" class=\"data row11 col1\" >0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row12\" class=\"row_heading level0 row12\" >9</th>\n",
       "      <td id=\"T_3961c_row12_col0\" class=\"data row12 col0\" >Neural_Net</td>\n",
       "      <td id=\"T_3961c_row12_col1\" class=\"data row12 col1\" >0.805000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3961c_level0_row13\" class=\"row_heading level0 row13\" >2</th>\n",
       "      <td id=\"T_3961c_row13_col0\" class=\"data row13 col0\" >Polynomial_SVM</td>\n",
       "      <td id=\"T_3961c_row13_col1\" class=\"data row13 col1\" >0.460000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f3b36321a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "s = df.style.background_gradient(cmap=cm)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33949f25-2354-4f25-b90a-a2fa503e16ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
